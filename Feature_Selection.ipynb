{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "pt = np.get_printoptions()['threshold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold-Based Methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.85, max_features=2000, min_df=0.1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(min_df=0.1, max_df=0.85, max_features=2000)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3  4  5  6\n",
       "0  1  0  0  0  0  0\n",
       "1  1  0  0  0  0  0\n",
       "2  1  0  0  0  0  0\n",
       "3  1  0  0  0  0  0\n",
       "4  1  0  0  0  0  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/Pokemon.csv')\n",
    "poke_gen = pd.get_dummies(df['Generation'])\n",
    "poke_gen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Features from ONE-HOT-ENCODED Features where variance is less than 0.15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0.15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "vt = VarianceThreshold(threshold=0.15)\n",
    "vt.fit(poke_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>select_feature</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>0.164444</td>\n",
       "      <td>0.114944</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.128373</td>\n",
       "      <td>0.163711</td>\n",
       "      <td>0.0919937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       1         2     3         4         5          6\n",
       "select_feature      True     False  True     False      True      False\n",
       "variance        0.164444  0.114944  0.16  0.128373  0.163711  0.0919937"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'variance': vt.variances_, \n",
    "              'select_feature': vt.get_support()},\n",
    "            index=poke_gen.columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  3  5\n",
       "0  1  0  0\n",
       "1  1  0  0\n",
       "2  1  0  0\n",
       "3  1  0  0\n",
       "4  1  0  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poke_gen_subset = poke_gen.iloc[:, vt.get_support()].head()\n",
    "poke_gen_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preceding feature subset depicts that features Gen 1,Gen 2, and Gen 3 have been finally selected out of the original six features  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Mutual Information Concept "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Feature set shape:', (569, 30))\n",
      "('Response class shape;', (569,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "bc_data = load_breast_cancer()\n",
    "bc_features = pd.DataFrame(bc_data.data, columns = bc_data.feature_names)\n",
    "bc_classes = pd.DataFrame(bc_data.target, columns=['IsMalignant'])\n",
    "\n",
    "# build featureset and response class labels \n",
    "bc_X = np.array(bc_features)\n",
    "bc_Y = np.array(bc_classes).T[0]\n",
    "print('Feature set shape:', bc_X.shape)\n",
    "print('Response class shape;', bc_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set data [shape: (569, 30)]\n",
      "(array([[ 17.99,  10.38, 122.8 , ...,   0.27,   0.46,   0.12],\n",
      "       [ 20.57,  17.77, 132.9 , ...,   0.19,   0.28,   0.09],\n",
      "       [ 19.69,  21.25, 130.  , ...,   0.24,   0.36,   0.09],\n",
      "       ...,\n",
      "       [ 16.6 ,  28.08, 108.3 , ...,   0.14,   0.22,   0.08],\n",
      "       [ 20.6 ,  29.33, 140.1 , ...,   0.26,   0.41,   0.12],\n",
      "       [  7.76,  24.54,  47.92, ...,   0.  ,   0.29,   0.07]]), '\\n')\n",
      "Feature names: \n",
      "(array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error',\n",
      "       'fractal dimension error', 'worst radius', 'worst texture',\n",
      "       'worst perimeter', 'worst area', 'worst smoothness',\n",
      "       'worst compactness', 'worst concavity', 'worst concave points',\n",
      "       'worst symmetry', 'worst fractal dimension'], dtype=object), '\\n')\n",
      "Response Class label data [shape: (569,)]\n",
      "(array([0, 0, 0, ..., 0, 0, 1]), '\\n')\n",
      "('Response variable name:', array(['IsMalignant'], dtype=object))\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold = 30)\n",
    "print('Feature set data [shape: '+str(bc_X.shape)+']')\n",
    "print(np.round(bc_X, 2), '\\n')\n",
    "print('Feature names: ')\n",
    "print(np.array(bc_features.columns), '\\n')\n",
    "print('Response Class label data [shape: '+str(bc_Y.shape)+']')\n",
    "print(bc_Y, '\\n')\n",
    "print('Response variable name:', np.array(bc_classes.columns))\n",
    "np.set_printoptions(threshold=pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Use Chi-Square test on this feature set and select top 15 best features out of the 30 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=15, score_func=<function chi2 at 0x7f5b436e7aa0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "skb = SelectKBest(score_func=chi2, k=15)\n",
    "skb.fit(bc_X, bc_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sorting the scores in order to see the most relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst area', 112598.43156405371),\n",
       " ('mean area', 53991.65592375093),\n",
       " ('area error', 8758.504705334482),\n",
       " ('worst perimeter', 3665.03541634059),\n",
       " ('mean perimeter', 2011.102863767906),\n",
       " ('worst radius', 491.6891574333226),\n",
       " ('mean radius', 266.1049171951782),\n",
       " ('perimeter error', 250.57189635982184),\n",
       " ('worst texture', 174.44939960571105),\n",
       " ('mean texture', 93.8975080986333)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_scores = [(item, score) \n",
    "                  for item, score in zip(\n",
    "                      bc_data.feature_names, skb.scores_)]\n",
    "sorted(feature_scores, key=lambda x: -x[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 15)\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean concavity' 'radius error' 'perimeter error' 'area error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst compactness' 'worst concavity' 'worst concave points']\n"
     ]
    }
   ],
   "source": [
    "select_features_kbest = skb.get_support()\n",
    "feature_names_kbest = bc_data.feature_names[select_features_kbest]\n",
    "feature_subset_df = bc_features[feature_names_kbest]\n",
    "bc_SX = np.array(feature_subset_df)\n",
    "print(bc_SX.shape)\n",
    "print(feature_names_kbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>radius error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.08</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.38</td>\n",
       "      <td>14.67</td>\n",
       "      <td>14.50</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.50</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.91</td>\n",
       "      <td>15.70</td>\n",
       "      <td>10.23</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.34</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.38</td>\n",
       "      <td>44.91</td>\n",
       "      <td>18.07</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21.16</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.69</td>\n",
       "      <td>4.30</td>\n",
       "      <td>93.99</td>\n",
       "      <td>29.17</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.65</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5.46</td>\n",
       "      <td>102.60</td>\n",
       "      <td>26.46</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean radius  mean texture  mean perimeter  mean area  mean concavity  \\\n",
       "20        13.08         15.71           85.63      520.0            0.05   \n",
       "21         9.50         12.44           60.34      273.9            0.03   \n",
       "22        15.34         14.26          102.50      704.4            0.21   \n",
       "23        21.16         23.04          137.20     1404.0            0.11   \n",
       "24        16.65         21.38          110.00      904.6            0.15   \n",
       "\n",
       "    radius error  perimeter error  area error  worst radius  worst texture  \\\n",
       "20          0.19             1.38       14.67         14.50          20.49   \n",
       "21          0.28             1.91       15.70         10.23          15.66   \n",
       "22          0.44             3.38       44.91         18.07          19.08   \n",
       "23          0.69             4.30       93.99         29.17          35.59   \n",
       "24          0.81             5.46      102.60         26.46          31.56   \n",
       "\n",
       "    worst perimeter  worst area  worst compactness  worst concavity  \\\n",
       "20            96.09       630.5               0.28             0.19   \n",
       "21            65.13       314.9               0.11             0.09   \n",
       "22           125.10       980.9               0.60             0.63   \n",
       "23           188.00      2615.0               0.26             0.32   \n",
       "24           177.00      2215.0               0.36             0.47   \n",
       "\n",
       "    worst concave points  \n",
       "20                  0.07  \n",
       "21                  0.06  \n",
       "22                  0.24  \n",
       "23                  0.20  \n",
       "24                  0.21  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(feature_subset_df.iloc[20:25], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's Use Simple Model Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy statistics with 5-fold cross validation\n",
      "('Model accuracy with complete feature set', (569, 30), ':', 0.9509041939207385)\n",
      "('Model accuracy with selected feature set', (569, 15), ':', 0.9526433243555215)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# build logistic regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "#evaluating accuracy for model built on full featureset\n",
    "full_feat_acc = np.average(cross_val_score(lr, bc_X, bc_Y, scoring='accuracy', cv=5))\n",
    "#evaluating accuracy for model built on selected featureset\n",
    "sel_feat_acc = np.average(cross_val_score(lr, bc_SX, bc_Y, scoring='accuracy', cv=5))\n",
    "\n",
    "print('Model accuracy statistics with 5-fold cross validation')\n",
    "print('Model accuracy with complete feature set', bc_X.shape, ':', full_feat_acc)\n",
    "print('Model accuracy with selected feature set', bc_SX.shape, ':', sel_feat_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy metrics clearly show us that we actually built a better model having accuracy of 95.26%\n",
    "when trained on the selected 15 feature subset as compared to the model built with the original 30 features\n",
    "which had an accuracy of 95.09%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "  n_features_to_select=15, step=1, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "lr = LogisticRegression()\n",
    "rfe = RFE(estimator=lr, n_features_to_select=15, step=1)\n",
    "rfe.fit(bc_X, bc_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean concavity' 'mean concave points'\n",
      " 'mean symmetry' 'texture error' 'perimeter error' 'area error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst compactness'\n",
      " 'worst concavity' 'worst concave points' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "select_features_rfe = rfe.get_support()\n",
    "feature_names_rfe = bc_data.feature_names[select_features_rfe]\n",
    "print(feature_names_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'area error',\n",
       " 'mean concavity',\n",
       " 'mean radius',\n",
       " 'mean texture',\n",
       " 'perimeter error',\n",
       " 'worst compactness',\n",
       " 'worst concave points',\n",
       " 'worst concavity',\n",
       " 'worst perimeter',\n",
       " 'worst radius',\n",
       " 'worst texture'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(feature_names_kbest) & set(feature_names_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we can see that 8 out of 15 features are common and have been chosen by both the feature\n",
    "selection techniques, which is definitely interesting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Based Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now use the random forest model to score\n",
    "and rank features based on their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(bc_X, bc_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst perimeter', 0.2850777940579633),\n",
       " ('worst concave points', 0.1581753725498124),\n",
       " ('area error', 0.1277718920428166),\n",
       " ('worst area', 0.09566227073381424),\n",
       " ('mean perimeter', 0.06920541869081835),\n",
       " ('mean concave points', 0.05056513993696928),\n",
       " ('concave points error', 0.02540278648608634),\n",
       " ('worst radius', 0.01743173931922087),\n",
       " ('mean texture', 0.017175112600948096),\n",
       " ('worst smoothness', 0.017063373468997854)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_scores = rfc.feature_importances_\n",
    "feature_importances = [(feature, score) \n",
    "            for feature, score in zip(\n",
    "                bc_data.feature_names, importance_scores)]\n",
    "sorted(feature_importances, key=lambda x: -x[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try to extract the first three principal components now from our breast cancer feature set of\n",
    "30 features using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# center the feature set\n",
    "bc_XC = bc_X - bc_X.mean(axis=0)\n",
    "\n",
    "# decompose using SVD\n",
    "U, S, VT = np.linalg.svd(bc_XC)\n",
    "\n",
    "# get principal components\n",
    "PC = VT.T\n",
    "\n",
    "# get first 3 principal components\n",
    "PC3 = PC[:, 0:3]\n",
    "PC3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1160.14,  -293.92,   -48.58],\n",
       "       [-1269.12,    15.63,    35.39],\n",
       "       [ -995.79,    39.16,     1.71],\n",
       "       ...,\n",
       "       [ -314.5 ,    47.55,    10.44],\n",
       "       [-1124.86,    34.13,    19.74],\n",
       "       [  771.53,   -88.64,   -23.89]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce feature set dimensionality\n",
    "np.round(bc_XC.dot(PC3), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform PCA on our breast cancer feature set leveraging scikit-learn's APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=3, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(bc_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98204467, 0.01617649, 0.00155751])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1160.14, -293.92,   48.58],\n",
       "       [1269.12,   15.63,  -35.39],\n",
       "       [ 995.79,   39.16,   -1.71],\n",
       "       ...,\n",
       "       [ 314.5 ,   47.55,  -10.44],\n",
       "       [1124.86,   34.13,  -19.74],\n",
       "       [-771.53,  -88.64,   23.89]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_pca = pca.transform(bc_X)\n",
    "np.round(bc_pca, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9280800307810695"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(cross_val_score(lr, bc_pca, bc_Y, scoring='accuracy', cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the preceding output that even though we used only three features derived from the\n",
    "principal components instead of the original 30 features, we still obtained a model accuracy close to 93%,\n",
    "which is quite decent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### “More data beats clever algorithms, but better data beats more data.”   —Peter Norvig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
